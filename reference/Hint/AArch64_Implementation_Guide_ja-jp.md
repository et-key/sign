# Sign言語 AArch64実装戦略：包括的仕様

## 1. はじめに

本ドキュメントでは、Sign言語のAArch64アーキテクチャ向け実装について、設計原則から戦略的アプローチまで包括的に解説します。Sign言語の哲学である「見えない強さ」を実現するため、シンプルながらも高効率な実装戦略を採用します。

## 2. 設計哲学：シンプルさの重視

### 2.1 シンプルさを重視したAArch64実装

シンプルなアーキテクチャを保つという哲学は非常に重要です。場合分けによる最適化は複雑性を増し、理解しづらく、バグの原因にもなりがちです。

1. **一貫した二重スタック構造**
   - データスタック：明確に定義されたレジスタセット（X8-X15）を専用に
   - コールスタック：標準的なSPベースのスタック
   - 例外なく一貫して適用する原則

2. **明確なレジスタ割り当て**
   - データスタック操作用レジスタ
   - 一時値保持用レジスタ
   - 状態管理用レジスタ
   - 常に同じ役割、同じ動作パターン

3. **一貫した呼び出し規約**
   - すべての関数で同じ引数渡し方式
   - 一様なスタックフレーム構造
   - シンプルで予測可能なレジスタ保存ルール

このアプローチならば、実装の複雑さを最小限に抑えつつ、Sign言語の本質を反映したアーキテクチャが実現できます。「単なる副作用」による最適化に頼らず、原則に基づいた一貫性のある設計は長期的には大きな利点をもたらします：

### 2.2 利点

このアプローチによる利点：

- バグの発生率低減
- 開発効率の向上
- 拡張性の確保
- 学習コストの削減

## 3. 二重スタック構造：パフォーマンス分析

Sign言語の二重スタック構造（データスタックとコールスタックの分離）がCの標準的な実行モデルと比較して高速かどうか、詳細に分析します。

### 3.1 両方のモデルの比較

#### 通常のCの実行モデル
- **単一スタック**: 関数呼び出し情報とローカル変数が同じスタック上に混在
- **レジスタ使用**: 呼び出し規約に従った汎用的使用
- **メモリアクセス**: ローカル変数へのアクセスはスタックメモリを経由

#### Sign言語の二重スタック構造
- **データスタック**: 値を専用レジスタセット(X8-X15)に保持
- **コールスタック**: 関数呼び出し情報のみをSPベースのスタックで管理
- **明確なレジスタ割り当て**: 用途別の専用レジスタ

### 3.2 パフォーマンス優位点

#### 3.2.1 メモリアクセス削減
```assembly
# C方式 (スタックフレーム使用)
LDR X0, [SP, #16]    // 変数aロード
LDR X1, [SP, #24]    // 変数bロード
ADD X0, X0, X1       // 計算
STR X0, [SP, #32]    // 結果保存

# Sign方式 (データスタックレジスタ使用)
ADD X9, X8, X10      // X8=a, X10=b, 結果はX9に
```

Sign方式では、値がレジスタに留まるため、メモリアクセス命令が大幅に削減されます。

#### 3.2.2 キャッシュ効率の向上
- データスタックがレジスタ内にあることで、キャッシュミスが減少
- レジスタは実質的に「L0キャッシュ」として機能

#### 3.2.3 パイプライン効率の向上
- 予測可能なレジスタ使用パターンによりCPUパイプラインの効率が上昇
- メモリアクセス待ちによるストールが減少

#### 3.2.4 SIMD命令との相性
- データスタックモデルは、リスト操作の自然なSIMD化に適合
- 例: `[* 2,] 1 2 3 4` のような操作をNEON命令で効率的に実行可能

### 3.3 具体的な速度比較例

#### 例1: 単純な数値計算 `(a+b)*(c+d)`

```assembly
# C方式
LDR X0, [X29, #a_offset]
LDR X1, [X29, #b_offset]
ADD X0, X0, X1
LDR X1, [X29, #c_offset]
LDR X2, [X29, #d_offset]
ADD X1, X1, X2
MUL X0, X0, X1

# Sign方式 (X8=a, X9=b, X10=c, X11=d)
ADD X12, X8, X9      // a+b
ADD X13, X10, X11    // c+d
MUL X0, X12, X13     // (a+b)*(c+d)
```

**結果**: Sign方式はメモリアクセス命令が4回少なく、理論的には約40%高速

#### 例2: リスト処理 `map (* 2) [1,2,3,4]`

```assembly
# C方式 (単純ループ実装)
loop:
    LDR W0, [X0], #4    // リスト要素をロード&ポインタ更新
    LSL W0, W0, #1      // 2倍
    STR W0, [X1], #4    // 結果に保存&ポインタ更新
    SUBS X2, X2, #1     // カウンタ減少
    B.NE loop           // 繰り返し

# Sign方式 (データスタックレジスタ使用)
LSL X8, X8, #1        // X8 = X8 * 2 (要素1)
LSL X9, X9, #1        // X9 = X9 * 2 (要素2)
LSL X10, X10, #1      // X10 = X10 * 2 (要素3)
LSL X11, X11, #1      // X11 = X11 * 2 (要素4)
```

**結果**: Sign方式はループオーバーヘッドなしで、ブランチミス予測も発生せず、理論的には3倍以上高速

#### 例3: SIMD最適化との組み合わせ

```assembly
# Sign方式 (NEON SIMD使用)
LD4 {v0.4s}, [x0]          // 4つの要素をロード
MUL v0.4s, v0.4s, v1.4s    // すべてを一度に乗算
ST4 {v0.4s}, [x0]          // 結果を保存
```

Sign言語のリストベースの統一データモデルは、このようなSIMD最適化と自然に調和します。

#### 3.3.1 MAP演算の自動SIMD化

Sign言語のMAP演算は、AArch64 NEON命令への自動変換が可能です：

```assembly
# 元のSign言語コード: [* 2,] [1, 2, 3, 4, 5, 6, 7, 8]

# 自動生成されるSIMD最適化コード
ld1 {v0.2d, v1.2d}, [x0]     // 8要素を2つのベクタレジスタにロード
lsl v0.4s, v0.4s, #1         // 前半4要素を2倍（並列演算）
lsl v1.4s, v1.4s, #1         // 後半4要素を2倍（並列演算）
st1 {v0.2d, v1.2d}, [x1]     // 結果を保存
```

**自動変換の条件**：
- 要素数が4の倍数
- 同一演算の連続適用
- データ依存関係なし

#### 3.3.2 FOLD演算の自動並列化

FOLD演算（畳み込み）も効率的な並列処理に自動変換されます：

```assembly
# 元のSign言語コード: [+] [1, 2, 3, 4, 5, 6, 7, 8]

# 自動生成される並列畳み込みコード
ld1 {v0.4s, v1.4s}, [x0]     // 8要素をロード
add v0.4s, v0.4s, v1.4s      // 4+4要素の並列加算: [1+5, 2+6, 3+7, 4+8]
addp v0.4s, v0.4s, v0.4s     // ペア加算: [(1+5)+(2+6), (3+7)+(4+8), ...]
addp v0.2s, v0.2s, v0.2s     // 最終的な水平加算
fmov w0, s0                  // 結果をスカラレジスタに移動
```

#### 3.3.3 マルチコア処理への自動分散

大きなデータセットでは、複数のコアに自動分散されます：

- **分散条件**: 要素数 > 64かつ演算コスト > しきい値
- **分散戦略**: データ並列（各コアが異なるデータ範囲を処理）
- **同期方式**: work-stealing queue による動的負荷分散

#### 3.3.4 AArch64最適化の利点

このSIMD/並列化により以下の性能向上が実現されます：

- **SIMD効果**: 単一命令で4-8要素を同時処理
- **並列効果**: マルチコアでの線形スケーリング
- **キャッシュ効率**: 連続メモリアクセスパターン
- **分岐削減**: ループ展開による制御フローの最適化

### 3.4 データスタック容量と長大リスト処理戦略

#### 3.4.1 データスタックレジスタの容量制限

**基本容量**：
- データスタック専用レジスタ：X8-X15（8個）
- 各レジスタ：64ビット（8バイト）
- 基本数値データ：最大8要素まで
- ポインタ参照：実質無制限（メモリ許容範囲内）

```assembly
# 基本的なデータスタック使用例
# [1, 2, 3, 4, 5, 6, 7, 8] の場合
mov x8, #1
mov x9, #2
mov x10, #3
mov x11, #4
mov x12, #5
mov x13, #6
mov x14, #7
mov x15, #8
```

#### 3.4.2 長大リスト処理の階層戦略

##### レベル1：レジスタ内完結処理（1-8要素）
```assembly
# 小規模リスト：レジスタ内完結
# [* 2,] [1, 2, 3, 4] の場合
lsl x8, x8, #1    // 1 * 2
lsl x9, x9, #1    // 2 * 2
lsl x10, x10, #1  // 3 * 2
lsl x11, x11, #1  // 4 * 2
```

##### レベル2：NEONベクトル処理（9-32要素）
```assembly
# 中規模リスト：NEONレジスタ活用
# V0-V7（8個の128ビットレジスタ）で最大32個の32ビット値を処理
ld1 {v0.4s, v1.4s, v2.4s, v3.4s}, [x0]  // 16要素ロード
shl v0.4s, v0.4s, #1   // 4要素を並列で2倍
shl v1.4s, v1.4s, #1   // 4要素を並列で2倍
shl v2.4s, v2.4s, #1   // 4要素を並列で2倍
shl v3.4s, v3.4s, #1   // 4要素を並列で2倍
st1 {v0.4s, v1.4s, v2.4s, v3.4s}, [x1]  // 結果保存
```

##### レベル3：チャンク分割処理（33要素以上）
```assembly
# 大規模リスト：チャンク単位での処理
# リストを32要素ずつに分割して順次処理
.process_large_list:
    mov x2, #32              // チャンクサイズ
    cmp x1, x2               // 残り要素数チェック
    b.lt .process_remainder  // 32未満なら残り処理へ
    
    // 32要素のNEON処理
    bl .process_32_elements
    add x0, x0, #128         // 次のチャンクへ（32要素×4バイト）
    sub x1, x1, #32          // 残り要素数更新
    b .process_large_list
    
.process_remainder:
    // 残り要素をレジスタまたはNEONで処理
    bl .process_small_chunk
```

#### 3.4.3 スマートスピル戦略

##### 使用頻度ベースのスピル
```assembly
# 頻繁に使用される値をレジスタに保持
# 使用頻度の低い値をメモリにスピル
.smart_spill:
    # 使用頻度解析結果に基づく配置
    # 高頻度: X8-X11（即座にアクセス可能）
    # 中頻度: X12-X15（1サイクルアクセス）
    # 低頻度: スタックメモリ（2-3サイクルアクセス）
    
    ldr x16, [sp, #spill_slot_1]  // 低頻度データの復帰
    # 計算実行
    str x15, [sp, #spill_slot_2]  // 一時的にスピル
```

##### プリディクティブスピル
```assembly
# 次に必要になるデータを予測してプリロード
.predictive_management:
    # ループ展開による予測的データ管理
    prfm pldl1keep, [x0, #128]   // 次のデータをプリフェッチ
    ld1 {v4.4s}, [x0, #64]       // 次の処理用データをロード
    # 現在の処理を実行
    st1 {v0.4s}, [x1], #16       // 結果保存と同時に次へ
```

#### 3.4.4 動的処理モード切替

##### コンパイル時判定
```c
// 疑似C++コード：コンパイル時の最適化判定
template<size_t N>
constexpr auto select_processing_mode() {
    if constexpr (N <= 8) {
        return register_mode{};
    } else if constexpr (N <= 32) {
        return simd_mode{};
    } else {
        return chunked_mode{};
    }
}
```

##### 実行時適応
```assembly
# 実行時サイズ判定と処理モード選択
.adaptive_processing:
    cmp x1, #8               // 要素数が8以下？
    b.le .register_mode      // レジスタモード
    cmp x1, #32              // 要素数が32以下？
    b.le .simd_mode          // SIMDモード
    b .chunked_mode          // チャンクモード

.register_mode:
    # レジスタベース処理
    bl .process_with_registers
    ret

.simd_mode:
    # NEONベース処理
    bl .process_with_neon
    ret

.chunked_mode:
    # チャンク分割処理
    bl .process_with_chunks
    ret
```

#### 3.4.5 メモリ効率最適化

##### キャッシュライン最適化
```assembly
# キャッシュライン（64バイト）に整合したアクセス
.cache_optimized_access:
    # 64バイト境界でのアラインメント
    and x2, x0, #~63         // 64バイト境界に整列
    ld1 {v0.2d, v1.2d, v2.2d, v3.2d}, [x2]  // 64バイト一括ロード
    # 必要な部分のみを抽出して処理
```

##### プリフェッチ戦略
```assembly
# 効率的なプリフェッチパターン
.prefetch_strategy:
    prfm pldl1keep, [x0, #128]   // L1キャッシュにプリフェッチ
    prfm pldl2keep, [x0, #256]   // L2キャッシュにプリフェッチ
    prfm pstl1keep, [x1, #128]   // 書き込み先もプリフェッチ
```

#### 3.4.6 実装効果とベンチマーク予測

##### 性能特性
| リストサイズ | 処理モード | 予想性能（C比） | 主要最適化要素 |
|-------------|-----------|----------------|---------------|
| 1-8要素 | レジスタ直接 | 200-400% | メモリアクセス削減 |
| 9-32要素 | NEON並列 | 500-800% | SIMD並列処理 |
| 33-128要素 | ハイブリッド | 300-600% | チャンク+プリフェッチ |
| 129要素以上 | ストリーミング | 150-300% | キャッシュ効率化 |

##### メモリ使用量
- **レジスタモード**: 追加メモリ不要（64バイト以内）
- **SIMDモード**: 一時領域256バイト（NEONレジスタ分）
- **チャンクモード**: 作業領域128バイト + プリフェッチバッファ256バイト

#### 3.4.7 自動チューニング機構

##### プロファイリングベース最適化
```assembly
# 実行時プロファイリングによる自動調整
.profile_based_optimization:
    # 実行回数と処理時間を記録
    mrs x2, cntvct_el0       // タイマー読み取り
    # 処理実行
    mrs x3, cntvct_el0       // 処理後タイマー
    sub x4, x3, x2           // 実行時間計算
    # 統計情報更新
    bl .update_performance_stats
```

この階層戦略により、Sign言語は小規模な数値リストから大規模なデータセットまで、一貫した高性能を実現できます。特に重要なのは、プログラマがデータサイズを意識せずに同じ記法でプログラムを書けることで、言語の「見えない強さ」の哲学が実現されることです。

### 3.5 潜在的な課題と対策

#### 3.5.1 C ABIとの互換性
- 外部C関数呼び出し時に変換オーバーヘッド発生
- ただし内部コードでは一貫して高速

#### 3.5.2 コンテキスト切り替えコスト
- より多くのレジスタの保存/復元が必要
- 階層戦略により、必要最小限のレジスタのみ保存する最適化が可能

## 4. スコープベースのメモリ管理戦略

### 4.1 メモリ管理の階層

Sign言語では、スコープに基づいた3層のメモリ管理を実装します：

1. **無名（即時開放）**
   - スタック上で完結
   - 式の評価が終わると即座に解放
   - 最も効率的なメモリ使用
   - AArch64のレジスタ内で完結する可能性も高い

2. **ローカル（ファイル単位）**
   - ファイルの実行が終了すると開放
   - 必要に応じてヒープ、または外側のスタックフレーム
   - ファイル単位のモジュール性を反映
   - コンパイル時の最適化の余地が大きい

3. **エクスポート（プロジェクト単位）**
   - 前置#演算子で定義された変数/関数
   - プロジェクト全体の実行終了まで保持
   - ヒープ上に確保する必要がある
   - 複数のファイル間での共有リソース

そして、OSとして動作するプロジェクトは、エクスポートされたリソースは永続的ということになります。これはシステム変数やグローバルリソースとして考えると理にかなっています。

この階層的なメモリ管理は、Sign言語の設計思想と非常に整合性があり、同時に実行効率も確保できます。スコープの明確な区分けによって、コンパイラは各変数の寿命を正確に把握し、最適なメモリ配置を決定できます。

AArch64上での実装では、これらの区分に応じた最適化（レジスタ割り当て、スタックフレーム設計、ヒープアロケーション）が可能になり、理論的な美しさと実行効率を両立できるでしょう。

### 4.2 領域ベースモデルとSign言語の親和性

#### 4.2.1 スコープ階層との自然な対応
- 無名スコープ → 一時領域（レジスタまたは一時スタック）
- ローカルスコープ → ファイル領域（ファイル実行終了で一括解放）
- エクスポートスコープ → グローバル領域（プログラム終了まで維持）

#### 4.2.2 一括割り当て・解放の効率性
- 領域単位での一括操作により断片化を回避
- 個別オブジェクト追跡のオーバーヘッドなし
- ベアメタル環境での予測可能なメモリ使用

#### 4.2.3 言語設計との整合性
- 「見えない強さ」の哲学にマッチ
- プログラマは明示的なメモリ管理を意識せず
- コンパイラが適切な領域割り当てを自動決定

### 4.3 実装アプローチ

具体的な実装では以下の戦略が有効でしょう：

#### 4.3.1 領域プール設計
- 各スコープタイプに対応した固定サイズプール
- アロケータはシンプルなバンプポインタ方式
- 領域内ではアロケーションのみ、解放は領域単位

#### 4.3.2 コンパイル時最適化
- 静的解析で各変数の最適な領域を決定
- スタック割り当て可能な一時オブジェクトの検出
- 不要なヒープアロケーションの排除

#### 4.3.3 内部フラグメンテーション対策
- 短命オブジェクト用の小さい領域
- 長命オブジェクト用の大きい領域
- 領域サイズの動的調整機能

### 4.4 ベアメタル環境での実装

AArch64向けベアメタル実装では：

```assembly
// 領域初期化（例：ファイルスコープ）
mov x0, #REGION_SIZE
bl alloc_region
mov x20, x0  // 領域ベースアドレスをx20に保持

// 領域内割り当て（シンプルなバンプアロケータ）
mov x0, x20
add x1, x0, #ALLOCATION_SIZE
str x1, [x0, #OFFSET_NEXT_FREE]
add x0, x0, #HEADER_SIZE

// 領域解放（ファイル実行終了時）
mov x0, x20
bl free_region
```

このアプローチでは、複雑なGCロジックなしでSign言語の実装が可能になります。領域ベースモデルはベアメタル環境で特に効果を発揮し、予測可能なパフォーマンスと低オーバーヘッドを実現できるでしょう。

## 5. 結論

### 5.1 理論的な速度向上

**Sign言語の二重スタック構造は、以下の条件下で通常のC方式より高速**:

1. **式の評価**: 特に四則演算などの連続した演算処理
2. **小〜中規模のリスト操作**: レジスタ内で完結する場合
3. **関数型プログラミングパターン**: MAP、FOLD、FILTERなどの高階関数

**理論的な速度向上:**
- 単純な算術演算: 約20-40%の速度向上
- リスト操作: 条件によっては数倍の速度向上
- SIMD最適化との組み合わせ: 最大10倍以上の速度向上も可能

### 5.2 設計統合の効果

Sign言語のAArch64実装戦略は、シンプルさを重視しながらも高いパフォーマンスを実現する設計となっています。二重スタック構造とスコープベースメモリ管理により、特に埋め込みシステムやシステムプログラミングなど、低レベルの最適化が重要な環境で大きな利点をもたらします。

データスタックレジスタの一貫した使用は、キャッシュ効率とCPUパイプラインの最適化にも寄与し、全体的なパフォーマンスを向上させる可能性が高いと言えます。この実装戦略により、Sign言語は理論的に美しいだけでなく、実際の計算環境で高効率に動作する言語として大きな可能性を秘めています。